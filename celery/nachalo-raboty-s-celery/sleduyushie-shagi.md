# Следующие шаги

Руководство «[Первые шаги с Celery](pervye-shagi-s-celery.md)» намеренно сведено к минимуму. В этом руководстве я более подробно покажу, что предлагает Celery, в том числе как добавить поддержку Celery для вашего приложения и библиотеки.

В этом документе не описаны все функции и рекомендации Celery, поэтому рекомендуется также прочитать [Руководство пользователя](../rukovodstvo-polzovatelya-celery/).



_Здесь должно быть оглавление..._

## Использование Celery в вашем приложении

### Наш проект

Макет проекта:

```bash
proj/__init__.py
    /celery.py
    /tasks.py
```

#### proj/celery.py

```python
from celery import Celery

app = Celery('proj',
             broker='amqp://',
             backend='rpc://',
             include=['proj.tasks'])

# Дополнительная конфигурация, см. руководство пользователя приложения.
app.conf.update(
    result_expires=3600,
)

if __name__ == '__main__':
    app.start()
```

В этом модуле вы создали наш экземпляр Celery (иногда называемый приложением **app**). Чтобы использовать Celery в своем проекте, вы просто импортируете этот экземпляр.

* Аргумент **broker** указывает URL-адрес используемого брокера. Дополнительную информацию см. в разделе [Выбор брокера](pervye-shagi-s-celery.md#vybor-brokera).
* Аргумент **backend** указывает используемую серверную часть результата. Он используется для отслеживания состояния задач и результатов. Хотя результаты по умолчанию отключены, я использую здесь серверную часть результатов RPC, потому что позже я продемонстрирую, как работает получение результатов. Возможно, вы захотите использовать другой бэкенд для своего приложения. Все они имеют разные сильные и слабые стороны. Если вам не нужны результаты, лучше их отключить. Результаты также можно отключить для отдельных задач, установив параметр `@task(ignore_result=True)`. Дополнительные сведения см. в разделе [Сохранение результатов](pervye-shagi-s-celery.md#sokhranenie-rezultatov).
* Аргумент **include** — это список модулей, которые нужно импортировать при запуске воркера. Вам нужно добавить сюда наш модуль задач, чтобы воркер смог найти наши задачи.

#### proj/tasks.py

```python
from .celery import app

@app.task
def add(x, y):
    return x + y

@app.task
def mul(x, y):
    return x * y

@app.task
def xsum(numbers):
    return sum(numbers)
```

### Запуск воркера

Программу **celery** можно использовать для запуска воркера (вам нужно запустить воркера в каталоге выше **proj**):

```bash
$ celery -A proj worker -l INFO
```

При запуске воркера вы должны увидеть баннер и несколько сообщений:

```bash
--------------- celery@halcyon.local v4.0 (latentcall)
--- ***** -----
-- ******* ---- [Configuration]
- *** --- * --- . broker:      amqp://guest@localhost:5672//
- ** ---------- . app:         __main__:0x1012d8590
- ** ---------- . concurrency: 8 (processes)
- ** ---------- . events:      OFF (enable -E to monitor this worker)
- ** ----------
- *** --- * --- [Queues]
-- ******* ---- . celery:      exchange:celery(direct) binding:celery
--- ***** -----

[2012-06-08 16:23:51,078: WARNING/MainProcess] celery@halcyon.local has started.
```

* **broker** — это URL-адрес, который вы указали в аргументе _broker_ в нашем модуле celery. Вы также можете указать другого посредника в командной строке, используя параметр [`-b`](https://docs.celeryq.dev/en/stable/reference/cli.html#cmdoption-celery-b).
* **concurrency** — это количество рабочих процессов **prefork**, используемых для одновременной обработки ваших задач. Когда все они заняты выполнением работы, новым задачам придется ждать завершения одной из задач, прежде чем ее можно будет обработать. Число concurrency по умолчанию — это количество ЦП на этой машине (включая ядра). Вы можете указать собственный номер, используя параметр [`celery worker -c`](https://docs.celeryq.dev/en/stable/reference/cli.html#cmdoption-celery-worker-c). Рекомендуемого значения нет, так как оптимальное число зависит от ряда факторов, но если ваши задачи в основном связаны с вводом-выводом, вы можете попытаться увеличить его. Эксперименты показали, что увеличение числа ЦП более чем в два раза редко бывает эффективным и, скорее всего, приведет к снижению производительности. Включая пул **prefork** по умолчанию, Celery также поддерживает использование Eventlet, Gevent и выполнение в одном потоке (см. [Concurrency](https://docs.celeryq.dev/en/stable/userguide/concurrency/index.html#concurrency)).
* **events** — это параметр, который заставляет Celery отправлять сообщения мониторинга (события) для действий, происходящих в рабочем потоке. Они могут использоваться программами мониторинга, такими как celery events и Flower — монитор Celery в реальном времени, о котором вы можете прочитать в руководстве по мониторингу и управлению ([Monitoring and Management guide](https://docs.celeryq.dev/en/stable/userguide/monitoring.html#guide-monitoring)).
* **Queues** — это список очередей, из которых рабочий процесс будет потреблять задачи. Рабочим процессам можно указать потреблять из нескольких очередей одновременно, и это используется для маршрутизации сообщений к конкретным рабочим процессам в качестве средства обеспечения качества обслуживания, разделения задач и определения приоритетов, все это описано в Руководстве по маршрутизации ([Routing Guide](https://docs.celeryq.dev/en/stable/userguide/routing.html#guide-routing)).

Вы можете получить полный список аргументов командной строки, передав флаг **--help**:

```bash
$ celery worker --help
```

Эти параметры более подробно описаны в Руководстве для рабочих ([Workers Guide](https://docs.celeryq.dev/en/stable/userguide/workers.html#guide-workers)).

### Остановка воркера

Чтобы остановить воркер, просто нажмите **Control-c**. Список сигналов, поддерживаемых воркером, подробно описан в Руководстве воркеров ([Workers Guide](https://docs.celeryq.dev/en/stable/userguide/workers.html#guide-workers)).

#### На заднем фоне

В продакшене вам нужно будет запускать воркер в фоновом режиме, как подробно описано в <mark style="color:purple;">руководстве по демонизации</mark>.

Сценарии демонизации используют команду `celery multi` для запуска одного или нескольких рабочих процессов в фоновом режиме:

```bash
celery multi start w1 -A proj -l INFO
celery multi v4.0.0 (latentcall)
> Starting nodes...
    > w1.halcyon.local: OK
```

Вы также можете перезапустить его:

```bash
celery  multi restart w1 -A proj -l INFO
celery multi v4.0.0 (latentcall)
> Stopping nodes...
    > w1.halcyon.local: TERM -> 64024
> Waiting for 1 node.....
    > w1.halcyon.local: OK
> Restarting node w1.halcyon.local: OK
celery multi v4.0.0 (latentcall)
> Stopping nodes...
    > w1.halcyon.local: TERM -> 64052
```

или остановить его:

```bash
celery multi stop w1 -A proj -l INFO
```

Команда остановки является асинхронной, поэтому она не будет ждать завершения работы рабочего процесса. Вместо этого вы, вероятно, захотите использовать команду **stopwait**, которая гарантирует, что все текущие выполняемые задачи будут завершены перед выходом:

```bash
celery multi stopwait w1 -A proj -l INFO
```

{% hint style="info" %}
**celery multi** не хранит информацию о воркерах, поэтому вам нужно использовать те же аргументы командной строки при перезапуске. При остановке должны использоваться только одни и те же аргументы **pidfile** и **logfile**.
{% endhint %}

По умолчанию он создает файлы **pid** и **log** в текущем каталоге. Для защиты от запуска нескольких рабочих процессов друг над другом рекомендуется поместить их в отдельный каталог:

```bash
mkdir -p /var/run/celery

mkdir -p /var/log/celery

celery multi start w1 -A proj -l INFO --pidfile=/var/run/celery/%n.pid \
                                        --logfile=/var/log/celery/%n%I.log
```

С помощью команды **multi** вы можете запустить несколько воркеров, а также имеется мощный синтаксис командной строки для указания аргументов для разных воркеров, например:

```bash
celery multi start 10 -A proj -l INFO -Q:1-3 images,video -Q:4,5 data \
    -Q default -L:4,5 debug
```

Дополнительные примеры см. в модуле <mark style="color:purple;">multi</mark> в справочнике по API.

#### Об аргументе --app

Аргумент `--app` указывает используемый экземпляр приложения Celery в виде `module.path:attribute`.

Но он также поддерживает сокращенную форму. Если указано только имя пакета, он попытается найти экземпляр приложения в следующем порядке:

С `--app=proj`:

1. атрибут с именем `proj.app` или
2. атрибут с именем `proj.celery` или
3. любой атрибут в модуле `proj`, где значением является приложение **Celery**, или

Если ни один из них не будет найден, он попытается использовать подмодуль с именем `proj.celery`:

1. атрибут с именем `proj.celery.app` или
2. атрибут с именем `proj.celery.celery` или
3. Любой атрибут в модуле `proj.celery`, значением которого является приложение **Celery**.

Эта схема имитирует приемы, используемые в документации, то есть `proj:app` для одного автономного модуля и `proj.celery:app` для более крупных проектов.

## Вызов задач

Вы можете вызвать задачу, используя метод `delay()`:

```python
from proj.tasks import add

add.delay(2, 2)
```

Этот метод на самом деле представляет собой ярлык со звездочкой для другого метода с именем `apply_async()`:

```python
add.apply_async((2, 2))
```

Последний позволяет вам указать параметры выполнения, такие как время запуска (обратный отсчет), очередь, в которую он должен быть отправлен, и т. д.:

```python
add.apply_async((2, 2), queue='lopri', countdown=10)
```

В приведенном выше примере задача будет отправлена в очередь с именем **lopri**, и задача будет выполнена не раньше, чем через **10 секунд** после отправки сообщения.

Применение задачи напрямую приведет к выполнению задачи в текущем процессе, поэтому сообщение не отправляется:

```python
>>> add(2, 2)
4
```

Эти три метода — `delay()`, `apply_async()` и применение (`__call__`) составляют API вызова Celery, который также используется для подписей (сигнатур).

Более подробный обзор Calling API можно найти в <mark style="color:purple;">Руководстве пользователя Calling</mark>.

Каждому вызову задачи будет присвоен уникальный идентификатор (**UUID**) — это идентификатор задачи.

Методы **delay** и **apply\_async** возвращают экземпляр <mark style="color:purple;">AsyncResult</mark>, который можно использовать для отслеживания состояния выполнения задач. Но для этого вам нужно включить <mark style="color:purple;">бэкенд результатов</mark>, чтобы состояние можно было где-то хранить.

Результаты отключены по умолчанию, потому что нет механизма обработки результатов, подходящего для любого приложения; чтобы выбрать один, вам нужно учитывать недостатки каждого отдельного бэкэнда. Для многих задач сохранение возвращаемого значения даже не очень полезно, поэтому разумно использовать его по умолчанию. Также обратите внимание, что бэкенды результатов не используются для мониторинга задач и воркеров: для этого Celery использует специальные сообщения о событиях (см. <mark style="color:purple;">Руководство по мониторингу и управлению</mark>).

Если у вас настроен сервер результатов, вы можете получить возвращаемое значение задачи:

```python
>>> res = add.delay(2, 2)
>>> res.get(timeout=1)
4
```

Вы можете найти идентификатор задачи, просмотрев атрибут **id**:

```python
>>> res.id
d6b3aea2-fb9b-4ebc-8da4-848818db9114
```

Вы также можете проверить исключение и трассировку, если задача вызвала исключение, фактически `result.get()` будет распространять любые ошибки по умолчанию:

```python
res = add.delay(2, '2')
res.get(timeout=1)
```

```python
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "celery/result.py", line 221, in get
    return self.backend.wait_for_pending(
  File "celery/backends/asynchronous.py", line 195, in wait_for_pending
    return result.maybe_throw(callback=callback, propagate=propagate)
  File "celery/result.py", line 333, in maybe_throw
    self.throw(value, self._to_remote_traceback(tb))
  File "celery/result.py", line 326, in throw
    self.on_ready.throw(*args, **kwargs)
  File "vine/promises.py", line 244, in throw
    reraise(type(exc), exc, tb)
  File "vine/five.py", line 195, in reraise
    raise value
TypeError: unsupported operand type(s) for +: 'int' and 'str'
```

Если вы не хотите, чтобы ошибки распространялись, вы можете отключить это, передав команду **propagate**:

```python
>>> res.get(propagate=False)
TypeError("unsupported operand type(s) for +: 'int' and 'str'")
```

В этом случае вместо этого он вернет сгенерированный экземпляр исключения, поэтому, чтобы проверить, успешно ли выполнена задача, вам придется использовать соответствующие методы для экземпляра результата:

```python
>>> res.failed()
True

>>> res.successful()
False
```

Так как же он узнает, провалилась задача или нет? Это можно узнать, посмотрев на состояние задач **state**:

```python
>>> res.state
'FAILURE'
```

Задача может находиться только в одном состоянии, но может проходить через несколько состояний. Этапы типовой задачи могут быть:

```
PENDING -> STARTED -> SUCCESS
```

Запущенное состояние (_started_) — это особое состояние, которое записывается только в том случае, если параметр <mark style="color:purple;">task\_track\_started</mark> включен или если для задачи установлен параметр `@task(track_started=True)`.

Состояние ожидания (_pending_) на самом деле не является записанным состоянием, а скорее состоянием по умолчанию для любого неизвестного идентификатора задачи: это вы можете увидеть в этом примере:

```python
>>> from proj.celery import app

>>> res = app.AsyncResult('this-id-does-not-exist')
>>> res.state
'PENDING'
```

Если задача повторяется, этапы могут стать еще более сложными. Чтобы продемонстрировать, для задачи, которая повторяется два раза, этапы будут такими:

```
PENDING -> STARTED -> RETRY -> STARTED -> RETRY -> STARTED -> SUCCESS
```

Чтобы узнать больше о состояниях задач, см. раздел «<mark style="color:purple;">Состояния</mark>» в руководстве пользователя задач.

Вызов задач подробно описан в <mark style="color:purple;">Руководстве по вызову</mark>.

## Canvas: проектирование рабочих потоков

Вы только что узнали, как вызывать задачу, используя метод **delay** задач, и часто это все, что вам нужно. Но иногда вам может понадобиться передать сигнатуру вызова задачи другому процессу или в качестве аргумента другой функции, для чего Celery использует так называемые сигнатуры (_signatures_).

Сигнатура упаковывает аргументы и параметры выполнения одного вызова задачи таким образом, что ее можно передать функциям или даже сериализовать и отправить по сети.

Вы можете создать сигнатуру для задачи _add_, используя аргументы `(2, 2)` и обратный отсчет _10 секунд_ следующим образом:

```python
>>> add.signature((2, 2), countdown=10)
tasks.add(2, 2)
```

Также есть ярлык с использованием аргументов-звездочек:

```python
>>> add.s(2, 2)
tasks.add(2, 2)
```

### И снова вызов API…

Экземпляры сигнатуры также поддерживают вызывающий API, то есть у них есть методы **delay** и **apply\_async**.

Но есть разница в том, что в сигнатуре уже может быть указана сигнатура аргумента. Задача _add_ принимает два аргумента, поэтому сигнатура, указывающая два аргумента, будет полной сигнатурой:

```python
>>> s1 = add.s(2, 2)
>>> res = s1.delay()
>>> res.get()
4
```

Но вы также можете сделать неполные сигнатуры, чтобы создать то, что мы называем **partials**:

```python
#  incomplete partial: add(?, 2)
s2 = add.s(2)
```

**s2** теперь является частичной сигнатурой, для которой требуется еще один аргумент, и это можно решить при вызове подписи:

```python
# resolves the partial: add(8, 2)
>>> res = s2.delay(8)
>>> res.get()
10
```

Здесь вы добавили аргумент 8, который был добавлен к существующему аргументу 2, образуя полную сигнатуру `add(8, 2)`.

Аргументы ключевых слов также можно добавить позже; затем они объединяются с любыми существующими аргументами ключевого слова, но с новыми аргументами, имеющими приоритет:

```python
s3 = add.s(2, 2, debug=True)
s3.delay(debug=False)   # debug сейчас False.
```

Как уже говорилось, сигнатуры поддерживают вызывающий API: это означает, что

* `sig.apply_async(args=(), kwargs={}, **options)` - вызывает сигнатуру с необязательными частичными аргументами и частичными аргументами ключевого слова. Также поддерживает варианты частичного выполнения.
* `sig.delay(*args, **kwargs)` - версия со звездочками аргумента **apply\_async**. Любые аргументы будут добавляться к аргументам в сигнатуре, а аргументы ключевых слов объединяются с любыми существующими ключами.

Все это кажется очень полезным, но что вы на самом деле можете с этим сделать? Чтобы добраться до этого, я должен представить примитивы холста…

### Примитивы

* <mark style="color:purple;">group</mark>
* <mark style="color:purple;">chain</mark>
* <mark style="color:purple;">chord</mark>
* <mark style="color:purple;">map</mark>
* <mark style="color:purple;">starmap</mark>
* <mark style="color:purple;">chunks</mark>

Эти примитивы сами по себе являются сигнатурными объектами, поэтому их можно комбинировать любым количеством способов для создания сложных рабочих процессов.

{% hint style="info" %}
Эти примеры извлекают результаты, поэтому, чтобы попробовать их, вам нужно настроить серверную часть результатов. Приведенный выше пример проекта уже делает это (см. бэкэнд-аргумент для <mark style="color:purple;">Celery</mark>).
{% endhint %}

Давайте рассмотрим несколько примеров:

#### Группы (group)

<mark style="color:purple;">group</mark> вызывает список задач параллельно и возвращает специальный экземпляр результата, который позволяет просматривать результаты как группу и извлекать возвращаемые значения по порядку.

```python
>>> from celery import group
>>> from proj.tasks import add

>>> group(add.s(i, i) for i in range(10))().get()
[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]
```

Частичная группа

```python
>>> g = group(add.s(i) for i in range(10))
>>> g(10).get()
[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
```

#### Цепи (chain)

Задачи могут быть связаны друг с другом, так что после возврата одной задачи вызывается другая:

```python
>>> from celery import chain
>>> from proj.tasks import add, mul

# (4 + 4) * 8
>>> chain(add.s(4, 4) | mul.s(8))().get()
64
```

или частичная цепь:

```python
>>> # (? + 4) * 8
>>> g = chain(add.s(4) | mul.s(8))
>>> g(4).get()
64
```

Цепи также можно записать так:

```python
>>> (add.s(4, 4) | mul.s(8))().get()
64
```

#### Хорды (chord)

Хорда — это группа с обратным вызовом:

```python
>>> from celery import chord
>>> from proj.tasks import add, xsum

>>> chord((add.s(i, i) for i in range(10)), xsum.s())().get()
90
```

Группа, привязанная к другой задаче, будет автоматически преобразована в хорду:

```python
>>> (group(add.s(i, i) for i in range(10)) | xsum.s())().get()
90
```

Поскольку все эти примитивы относятся к типу **signature**, их можно комбинировать почти так, как вы хотите, например:

```python
>>> upload_document.s(file) | group(apply_filter.s() for filter in filters)
```

Не забудьте прочитать больше о рабочих процессах в <mark style="color:purple;">руководстве пользователя Canvas</mark>.

## Маршрутизация (routing)

**Celery** поддерживает все средства маршрутизации, предоставляемые AMQP, но также поддерживает простую маршрутизацию, при которой сообщения отправляются в именованные очереди.

Параметр <mark style="color:purple;">task\_routes</mark> позволяет маршрутизировать задачи по имени и хранить все централизованно в одном месте:

```python
app.conf.update(
    task_routes = {
        'proj.tasks.add': {'queue': 'hipri'},
    },
)
```

Вы также можете указать очередь во время выполнения с аргументом **queue** для **apply\_async**:

```python
>>> from proj.tasks import add
>>> add.apply_async((2, 2), queue='hipri')
```

Затем вы можете заставить воркер потреблять из этой очереди, указав параметр <mark style="color:purple;">celery worker -Q</mark>:

```bash
celery -A proj worker -Q hipri
```

Вы можете указать несколько очередей, используя список, разделенный запятыми. Например, вы можете заставить worker потреблять как из очереди по умолчанию, так и из очереди **hipri**, где очередь по умолчанию называется **celery** по историческим причинам:

```bash
celery -A proj worker -Q hipri,celery
```

Порядок очередей не имеет значения, так как воркер будет придавать равный вес очередям.

Чтобы узнать больше о маршрутизации, включая использование всех возможностей маршрутизации AMQP, см. <mark style="color:purple;">Руководство по маршрутизации</mark>.

## Удаленный контроль (remote control)

Если вы используете RabbitMQ (AMQP), Redis или Qpid в качестве брокера, вы можете контролировать и проверять воркер во время выполнения.

Например, вы можете увидеть, над какими задачами сейчас работает воркер:

```bash
celery -A proj inspect active
```

Это реализовано с помощью широковещательного обмена сообщениями, поэтому все команды удаленного управления получаются каждым воркером в кластере.

Вы также можете указать одного или нескольких воркеров для обработки запроса, используя параметр <mark style="color:purple;">--destination</mark>. Это список имен хостов воркеров, разделенных запятыми:

```bash
celery -A proj inspect active --destination=celery@example.com
```

Если **destination** не указан, каждый воркер будет действовать и отвечать на запрос.

Команда **celery inspect** содержит команды, которые ничего не меняют в воркере; он только возвращает информацию и статистику о том, что происходит внутри воркера. Список команд проверки, которые вы можете выполнить:

```bash
celery -A proj inspect --help
```

Затем есть команда **celery control**, которая содержит команды, которые на самом деле изменяют что-то в воркере во время выполнения:

```bash
celery -A proj control --help
```

Например, вы можете заставить воркеров включить сообщения о событиях (используемые для мониторинга задач и воркеров):

```bash
celery -A proj control enable_events
```

Когда события включены, вы можете запустить дампер событий, чтобы увидеть, что делают воркеры:

```bash
celery -A proj events --dump
```

или вы можете запустить интерфейс curses:

```bash
celery -A proj events
```

когда вы закончите мониторинг, вы можете снова отключить события:

```bash
celery -A proj control disable_events
```

Команда **celery status** также использует команды удаленного управления и показывает список онлайн-воркеров в кластере:

```bash
celery -A proj status
```

Подробнее о команде **celery** и мониторинге можно прочитать в <mark style="color:purple;">Руководстве по мониторингу</mark>.

## Временная зона (timezone)

Все время и даты, внутри и в сообщениях, используют часовой пояс **UTC**.

Когда воркер получает сообщение, например, с установленным обратным отсчетом, он преобразует это время UTC в местное время. Если вы хотите использовать часовой пояс, отличный от часового пояса системы, вы должны настроить его с помощью настройки <mark style="color:purple;">timezone</mark>:

```python
app.conf.timezone = 'Europe/London'
```

## Оптимизация

Конфигурация по умолчанию не оптимизирована для пропускной способности. По умолчанию он пытается найти средний путь между большим количеством коротких задач и меньшим количеством длинных задач, компромисс между пропускной способностью и справедливым планированием.

Если у вас есть строгие требования к справедливому планированию или вы хотите оптимизировать пропускную способность, вам следует прочитать <mark style="color:purple;">Руководство по оптимизации</mark>.

## Что делать сейчас?

Теперь, когда вы прочитали этот документ, вам следует перейти к [Руководству пользователя](../rukovodstvo-polzovatelya-celery/).

Там также есть <mark style="color:purple;">ссылка на API</mark>, если вы так склонны.
